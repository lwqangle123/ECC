{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.data import Dataset\n",
    "\n",
    "from deeprobust.graph.utils import get_train_val_test\n",
    "# loading cora dataset\n",
    "data = Dataset(root='/tmp/', name='citeseer', seed=15)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "# you can also split the data by yourself\n",
    "# idx_train, idx_val, idx_test = get_train_val_test(adj.shape[0], val_size=0.1, test_size=0.8)\n",
    "\n",
    "# loading acm dataset\n",
    "#data = Dataset(root='/tmp/', name='acm', seed=15)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "#np.random.bit_generator = np.random._bit_generator\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.defense import GAT\n",
    "from deeprobust.graph.targeted_attack import RND\n",
    "from deeprobust.graph.global_attack import DICE\n",
    "from deeprobust.graph.utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "idx_train, idx_val, idx_test = get_train_val_test(adj.shape[0], val_size=0.2, test_size=0.2, stratify=data.labels)\n",
    "\n",
    "\n",
    "idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.idx_train = idx_train\n",
    "data.idx_val = idx_val\n",
    "data.idx_test = idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = adj.shape[0]\n",
    "D = features.shape[1]\n",
    "shape = (N, D)\n",
    "mx = features\n",
    "indices = mx.nonzero()\n",
    "#mf = sp.csr_matrix((mx.data, (indices[0], indices[1])), shape=shape).tolil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== training GAT model ===\n",
      "Epoch 0, training loss: 1.7974687814712524\n",
      "Epoch 10, training loss: 0.8738367557525635\n",
      "Epoch 20, training loss: 0.7205302715301514\n",
      "Epoch 30, training loss: 0.6369431018829346\n",
      "Epoch 40, training loss: 0.5876106023788452\n",
      "Epoch 50, training loss: 0.5795077085494995\n",
      "Epoch 60, training loss: 0.5982430577278137\n",
      "Epoch 70, training loss: 0.6104787588119507\n",
      "Epoch 80, training loss: 0.5829026103019714\n",
      "Epoch 90, training loss: 0.5837940573692322\n",
      "=== early stopping at 99, loss_val = 0.6672727465629578 ===\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.data import Dpr2Pyg\n",
    "from deeprobust.graph.defense import GAT\n",
    "gat = GAT(nfeat=features.shape[1],\n",
    "              nhid=8, heads=8,\n",
    "              nclass=labels.max().item() + 1,\n",
    "              dropout=0.5, device='cpu')\n",
    "gat = gat.to('cpu')\n",
    "pyg_data = Dpr2Pyg(data) \n",
    "gat.fit(pyg_data.process(), train_iters=100, patience=100, verbose=True) \n",
    "output = gat.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "modified_adj_mat = np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "adj_mat = np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "adj_mat_total = np.zeros((20,np.shape(adj)[0],np.shape(adj)[0]))\n",
    "adj_ori = np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "for i in range(np.shape(adj)[0]):\n",
    "    a = adj[i].indices\n",
    "    for j in range(len(a)):\n",
    "        adj_ori[i,a[j]]=1\n",
    "tau=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [01:05<00:00,  1.51it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [01:08<00:00,  1.22it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [01:05<00:00,  1.21it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.93it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:53<00:00,  1.94it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:54<00:00,  1.94it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:52<00:00,  1.91it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:57<00:00,  1.89it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:53<00:00,  1.95it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 100/100 [00:54<00:00,  1.96it/s]\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/anaconda3/envs/deeprobust/lib/python3.7/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79258b9db4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mR_adj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMM_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mRr_adj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRr_adj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#recover error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#O1=gat.predict(features, Rr_adj).argmax(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Topology Attack\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from deeprobust.graph.global_attack import PGDAttack\n",
    "N=10\n",
    "M_adj = torch.zeros((1,np.shape(adj)[0]*np.shape(adj)[1]))\n",
    "for i in range(N):\n",
    "    model = PGDAttack(model=gat, nnodes=adj.shape[0], loss_type='CE', device='cpu').to('cpu')\n",
    "    B = 0.0001 + np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "    adj_n = np.logical_xor(torch.from_numpy(adj_ori), np.random.binomial(1,B)).float()+torch.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "    adj_nn = torch.triu(adj_n,diagonal=1)\n",
    "    adj_noise = adj_nn.T+adj_nn\n",
    "    model.attack(features, adj_noise, labels, idx_train, n_perturbations=100000)\n",
    "    M_adj = np.vstack((M_adj,model.modified_adj.reshape(1,np.shape(adj)[0]*np.shape(adj)[1])))\n",
    "\n",
    "MM_adj = M_adj[1:,:]\n",
    "R_adj=np.int64(sum(MM_adj)/N>tau)\n",
    "Rr_adj=R_adj.reshape(np.shape(adj)[0],np.shape(adj)[1])\n",
    "np.shape(np.where((Rr_adj-(adj_ori))!=0))[1]/(np.shape(adj)[0]*np.shape(adj)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n",
      "number of pertubations: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2052132701421801"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DICE Attack\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from deeprobust.graph.global_attack import PGDAttack\n",
    "N=21\n",
    "M_adj = np.zeros((1,np.shape(adj)[0]*np.shape(adj)[1]))\n",
    "adj_mm = np.zeros((np.shape(adj)[0],np.shape(adj)[1]))\n",
    "for i in range(N):\n",
    "    model = DICE()\n",
    "    B = 0.00015 + np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "    adj_n = np.logical_xor(torch.from_numpy(adj_ori), np.random.binomial(1,B)).float()+torch.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "    adj_nn = torch.triu(adj_n,diagonal=1)\n",
    "    adj_noise = adj_nn.T+adj_nn\n",
    "    adj_nnn = sp.csr_matrix(adj_noise).tocsr()\n",
    "    model.attack(adj_nnn, labels, n_perturbations=1000)\n",
    "    modified_adj=model.modified_adj\n",
    "    for ii in range(np.shape(modified_adj)[0]):\n",
    "                a = modified_adj[ii].rows           \n",
    "                for jj in range(len(a[0])):\n",
    "                    adj_mm[ii,a[0][jj]]=1    \n",
    "    M_adj = np.vstack((M_adj,adj_mm.reshape(1,np.shape(adj)[0]*np.shape(adj)[1])))\n",
    "\n",
    "MM_adj = M_adj[1:,:]\n",
    "R_adj=np.int64(sum(MM_adj)/N>tau)\n",
    "Rr_adj=R_adj.reshape(np.shape(adj)[0],np.shape(adj)[1])\n",
    "np.shape(np.where((Rr_adj-(adj_ori))!=0))[1]/(np.shape(adj)[0]*np.shape(adj)[1])#recover error\n",
    "\n",
    "data1=copy.copy(data)\n",
    "data1.adj = sp.csr_matrix(Rr_adj).tocsr()\n",
    "data1= Dpr2Pyg(data1).process()\n",
    "O1=gat.forward(data1).argmax(1)\n",
    "np.shape(np.where(O1!=O2))[1]/2110#misclassification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5150, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#model = PGDAttack(model=gat, nnodes=adj.shape[0], loss_type='CE', device='cpu').to('cpu')\n",
    "#from torch.nn import functional as F\n",
    "#data = pyg_data.process()\n",
    "#output = gat.forward(data)\n",
    "#loss = F.nll_loss(output[idx_train], torch.from_numpy(labels[idx_train]).type(torch.LongTensor))\n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_noise = np.int64(adj_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 573\n",
      "1 480\n",
      "2 628\n",
      "5 526\n",
      "3 206\n",
      "1 123\n",
      "5 436\n",
      "9 334\n",
      "12 408\n",
      "12 408\n",
      "number of pertubations: 80\n",
      "0\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "[21.38672986]\n",
      "1 231\n",
      "2 142\n",
      "5 614\n",
      "1 710\n",
      "9 487\n",
      "5 107\n",
      "3 86\n",
      "1 123\n",
      "2 122\n",
      "1 720\n",
      "2 294\n",
      "2 661\n",
      "3 337\n",
      "9 470\n",
      "4 118\n",
      "2 73\n",
      "2 774\n",
      "3 288\n",
      "6 22\n",
      "5 33\n",
      "1 388\n",
      "3 493\n",
      "2 467\n",
      "2 528\n",
      "3 753\n",
      "2 387\n",
      "5 472\n",
      "1 269\n",
      "5 436\n",
      "2 387\n",
      "1 215\n",
      "3 773\n",
      "5 589\n",
      "2 197\n",
      "4 778\n",
      "4 643\n",
      "1 703\n",
      "7 383\n",
      "4 570\n",
      "2 664\n",
      "4 405\n",
      "1 705\n",
      "1 261\n",
      "4 699\n",
      "4 643\n",
      "5 333\n",
      "1 157\n",
      "2 85\n",
      "7 87\n",
      "3 486\n",
      "1 430\n",
      "3 406\n",
      "4 413\n",
      "1 430\n",
      "3 672\n",
      "2 629\n",
      "2 259\n",
      "1 402\n",
      "3 637\n",
      "2 302\n",
      "3 623\n",
      "3 375\n",
      "4 91\n",
      "1 491\n",
      "4 795\n",
      "2 608\n",
      "2 271\n",
      "6 220\n",
      "12 299\n",
      "12 299\n",
      "number of pertubations: 80\n",
      "11\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "[21.38672986 21.46255924]\n",
      "6 727\n",
      "2 438\n",
      "2 189\n",
      "1 215\n",
      "6 783\n",
      "3 82\n",
      "7 497\n",
      "5 589\n",
      "1 632\n",
      "3 749\n",
      "1 571\n",
      "7 87\n",
      "1 632\n",
      "3 129\n",
      "1 462\n",
      "3 450\n",
      "3 429\n",
      "3 684\n",
      "12 694\n",
      "12 694\n",
      "number of pertubations: 80\n",
      "0\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "[21.38672986 21.46255924 21.53838863]\n",
      "2 181\n",
      "3 72\n",
      "1 675\n",
      "1 154\n",
      "3 288\n",
      "1 3\n",
      "5 132\n",
      "1 3\n",
      "5 361\n",
      "4 545\n",
      "2 20\n",
      "7 669\n",
      "3 19\n",
      "2 839\n",
      "2 578\n",
      "5 734\n",
      "3 21\n",
      "6 5\n",
      "3 258\n",
      "2 209\n",
      "4 765\n",
      "1 634\n",
      "3 455\n",
      "1 160\n",
      "3 120\n",
      "1 511\n",
      "2 477\n",
      "4 390\n",
      "1 609\n",
      "1 186\n",
      "3 205\n",
      "2 745\n",
      "2 686\n",
      "4 640\n",
      "1 419\n",
      "15 98\n",
      "15 98\n",
      "number of pertubations: 80\n",
      "0\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "[21.38672986 21.46255924 21.53838863 21.61421801]\n",
      "2 391\n",
      "1 287\n",
      "2 360\n",
      "2 647\n",
      "2 745\n",
      "3 379\n",
      "2 701\n",
      "1 814\n",
      "3 486\n",
      "3 801\n",
      "3 767\n",
      "3 416\n",
      "5 587\n",
      "3 461\n",
      "5 172\n",
      "2 102\n",
      "2 802\n",
      "3 427\n",
      "12 694\n",
      "12 694\n",
      "number of pertubations: 80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-3cc002fc9dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                         \u001b[0medge_index_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;31m#edge_index_e.astype(int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Random Attack\n",
    "import copy\n",
    "data = copy.copy(pyg_data.process())\n",
    "data1 = copy.copy(pyg_data.process())\n",
    "data2 = copy.copy(pyg_data.process())\n",
    "data3 = copy.copy(pyg_data.process())\n",
    "iter = 1\n",
    "u = np.array([])\n",
    "K=52\n",
    "while iter<1000:\n",
    "    k = random.randint(0,np.shape(idx_unlabeled)[0]-1)\n",
    "    target_node = idx_unlabeled[k]\n",
    "    assert target_node in idx_unlabeled\n",
    "    degrees = adj.sum(0).A1\n",
    "    print(int(degrees[target_node]),k)\n",
    "    if int(degrees[target_node])<10:\n",
    "        continue\n",
    "    u=np.hstack((u,target_node))\n",
    "    print(int(degrees[target_node]),k)\n",
    "    for j in range(1):\n",
    "        model = RND()\n",
    "        B = 0.0001 + np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "        adj_n = np.logical_xor(adj, np.random.binomial(1,B)).float()+torch.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "        adj_nn = torch.triu(adj_n,diagonal=1)\n",
    "        adj_noise = adj_nn.T+adj_nn\n",
    "        adj_nnn = sp.csr_matrix(adj_noise).tocsr()\n",
    "        adj_mat_e = np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "        #adj_mat = np.zeros((np.shape(adj)[0],np.shape(adj)[0]))\n",
    "        model.attack(adj_nnn, labels, idx_train, target_node, n_perturbations=80)#change ptb size here\n",
    "        modified_adj = model.modified_adj\n",
    "        #edge_index = np.zeros((1,2))\n",
    "        for i in range(1,K):\n",
    "            edge_index = np.zeros((1,2))\n",
    "            for ii in range(np.shape(adj)[0]):\n",
    "                a = modified_adj[ii].rows           \n",
    "                for jj in range(len(a[0])):\n",
    "                    adj_mat[ii,a[0][jj]]=1             \n",
    "                    if adj_mat[ii,a[0][jj]]==1:\n",
    "                        edge_index_e = np.array([ii,a[0][jj]])\n",
    "                        #edge_index_e.astype(int)\n",
    "                        edge_index = np.vstack((edge_index,edge_index_e))\n",
    "                        \n",
    "            edge_index = edge_index[1:,:]\n",
    "            edge_index = edge_index.T\n",
    "            edge_index = edge_index.astype(int)\n",
    "            edge_index = torch.from_numpy(edge_index)\n",
    "\n",
    "            data1.edge_index = edge_index\n",
    "            OP_1 = gat.forward(data1).argmax(1)[target_node]\n",
    "            Out_1=np.hstack((Out_1, OP_1))\n",
    "            #print(OP_1)\n",
    "            \n",
    "        \n",
    "        adj_mat_ee = np.int64(adj_mat_e/(K-1)>0.5)\n",
    "        len_reshape = int(np.shape(adj_mat_ee)[0]*np.shape(adj_mat_ee)[1])\n",
    "        error_e=len(np.where(adj_mat_ee.reshape(1,len_reshape)-adj_ori.reshape(1,len_reshape) !=0)[0])/(int(np.shape(adj_mat_ee)[0]))\n",
    "        error = np.hstack((error,error_e))\n",
    "        MRr = np.hstack((MRr,MR))\n",
    "        \n",
    "        edge_index_02 = np.zeros((1,2))\n",
    "        for ii in range(np.shape(adj_mat_ee)[0]):\n",
    "            for jj in range(np.shape(adj_mat_ee)[1]):\n",
    "\n",
    "                if adj_mat_ee[ii,jj]==1:\n",
    "                    edge_index_e_2 = np.array([ii,jj])\n",
    "                        #edge_index_e.astype(int)\n",
    "                    edge_index_02 = np.vstack((edge_index_02,edge_index_e_2))\n",
    "                    \n",
    "        edge_index_02 = edge_index_02[1:,:]\n",
    "        edge_index_02 = edge_index_02.T\n",
    "        edge_index_02 = edge_index_02.astype(int)\n",
    "        edge_index_02 = torch.from_numpy(edge_index_02)\n",
    "\n",
    "        data2.edge_index = edge_index_02\n",
    "        OP_2 = gat.forward(data2).argmax(1)[target_node]\n",
    "        Out_2=np.hstack((Out_2, OP_2))\n",
    "        print(OP_2)\n",
    "        \n",
    "        edge_index_03 = np.zeros((1,2))\n",
    "        for ii in range(np.shape(adj_ori)[0]):\n",
    "            for jj in range(np.shape(adj_ori)[1]):\n",
    "\n",
    "                if adj_ori[ii,jj]==1:\n",
    "                    edge_index_e_3 = np.array([ii,jj])\n",
    "                        #edge_index_e.astype(int)\n",
    "                    edge_index_03 = np.vstack((edge_index_03,edge_index_e_3))\n",
    "                    \n",
    "        edge_index_03 = edge_index_03[1:,:]\n",
    "        edge_index_03 = edge_index_03.T\n",
    "        edge_index_03 = edge_index_03.astype(int)\n",
    "        edge_index_03 = torch.from_numpy(edge_index_03)\n",
    "            \n",
    "        data3.edge_index = edge_index_03\n",
    "        OP_3 = gat.forward(data3).argmax(1)[target_node]\n",
    "        \n",
    "        Out_3=np.hstack((Out_3, OP_3))\n",
    "        print(OP_3)\n",
    "        #print(target_node, output_e2.argmax(1)[target_node])\n",
    "        error_3 = (OP_3-labels[target_node])\n",
    "        error_2 = (OP_3-OP_2)\n",
    "        error_1 = (OP_3-OP_1)\n",
    "        Error_3 = np.hstack((Error_3, error_3))\n",
    "        Error_2 = np.hstack((Error_2, error_2))\n",
    "        Error_1 = np.hstack((Error_1, error_1))\n",
    "    print(error)\n",
    "    #MRrs=np.hstack((MRrs,MRr))\n",
    "    #ERR=np.hstack((ERR,error))\n",
    "    iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pertubations: 8\n",
      "(3025, 1870)\n",
      "tensor([[-2.0488, -0.5839, -1.1602],\n",
      "        [-1.5482, -0.6928, -1.2476],\n",
      "        [-1.6864, -0.6142, -1.2956],\n",
      "        ...,\n",
      "        [-1.6784, -0.7289, -1.1060],\n",
      "        [-1.8741, -0.5094, -1.4039],\n",
      "        [-1.2342, -0.8546, -1.2606]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# train surrogate model\n",
    "degrees = adj.sum(0).A1\n",
    "n_perturbations = int(degrees[u]) # How many perturbations to perform. Default: Degree of the node\n",
    "#model = RND()\n",
    "#model.attack(adj, labels, idx_train, target_node, n_perturbations, verbose=False)\n",
    "\n",
    "\n",
    "# modified_adj = model.attack(adj, labels, idx_train, target_node, n_perturbations)\n",
    "model.add_nodes(features, adj, labels, idx_train, target_node, n_added=0,\n",
    "                               n_perturbations=n_perturbations)\n",
    "modified_adj = model.modified_adj\n",
    "modified_features = model.modified_features\n",
    "#modified_features = features\n",
    "gcn = GCN(nfeat=features.shape[1],\n",
    "                  nhid=16,\n",
    "                 nclass=labels.max().item() + 1,\n",
    "                  dropout=0.5, device=device)\n",
    "\n",
    "gcn = gcn.to(device)\n",
    "output = gcn.predict(modified_features, modified_adj)\n",
    "\n",
    "print(np.shape(modified_features))\n",
    "print(output)\n",
    "\n",
    "def test(adj, features, target_node):\n",
    "    ''' test on GCN '''\n",
    "    gcn = GCN(nfeat=features.shape[1],\n",
    "              nhid=16,\n",
    "              nclass=labels.max().item() + 1,\n",
    "              dropout=0.5, device=device)\n",
    "\n",
    "    gcn = gcn.to(device)\n",
    "\n",
    "    gcn.fit(features, adj, labels, idx_train)\n",
    "    gcn.eval()\n",
    "    output = gcn.predict()\n",
    "    probs = torch.exp(output[[target_node]])[0]\n",
    "    print('probs: {probs.detach().cpu().numpy()}')\n",
    "\n",
    "    labels_tensor = torch.LongTensor(labels).to(device)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels_tensor[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels_tensor[idx_test])\n",
    "\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_test(adj, features, target_node, gcn=None):\n",
    "    if gcn is None:\n",
    "        # test on GCN (poisoning attack)\n",
    "        gcn = GCN(nfeat=features.shape[1],\n",
    "                  nhid=16,\n",
    "                  nclass=labels.max().item() + 1,\n",
    "                  dropout=0.5, device=device)\n",
    "\n",
    "        gcn = gcn.to(device)\n",
    "\n",
    "        gcn.fit(features, adj, labels, idx_train, idx_val, patience=30)\n",
    "        gcn.eval()\n",
    "        output = gcn.predict()\n",
    "    else:\n",
    "        # test on GCN (evasion attack)\n",
    "        output = gcn.predict(features, adj)\n",
    "    probs = torch.exp(output[[target_node]])\n",
    "    #print(output)\n",
    "    #print(output.argmax(1))\n",
    "    #print(output.argmax(1)[target_node], labels[target_node])\n",
    "\n",
    "    # acc_test = accuracy(output[[target_node]], labels[target_node])\n",
    "    acc_test = (output.argmax(1)[target_node] == labels[target_node])\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_nodes(target_gcn=None):\n",
    "    '''\n",
    "    selecting nodes as reported in nettack paper:\n",
    "    (i) the 10 nodes with highest margin of classification, i.e. they are clearly correctly classified,\n",
    "    (ii) the 10 nodes with lowest margin (but still correctly classified) and\n",
    "    (iii) 20 more nodes randomly\n",
    "    '''\n",
    "\n",
    "    if target_gcn is None:\n",
    "        target_gcn = GCN(nfeat=features.shape[1],\n",
    "                  nhid=16,\n",
    "                  nclass=labels.max().item() + 1,\n",
    "                  dropout=0.5, device=device)\n",
    "        target_gcn = target_gcn.to(device)\n",
    "        target_gcn.fit(features, adj, labels, idx_train, idx_val, patience=30)\n",
    "    target_gcn.eval()\n",
    "    output = target_gcn.predict()\n",
    "\n",
    "    margin_dict = {}\n",
    "    for idx in idx_test:\n",
    "        margin = classification_margin(output[idx], labels[idx])\n",
    "        if margin < 0: # only keep the nodes correctly classified\n",
    "            continue\n",
    "        margin_dict[idx] = margin\n",
    "    sorted_margins = sorted(margin_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "    high = [x for x, y in sorted_margins[: 10]]\n",
    "    low = [x for x, y in sorted_margins[-10: ]]\n",
    "    other = [x for x, y in sorted_margins[10: -10]]\n",
    "    other = np.random.choice(other, 20, replace=False).tolist()\n",
    "\n",
    "    return high + low + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_test_evasion():\n",
    "    # test on 40 nodes on evasion attack\n",
    "    target_gcn = GCN(nfeat=features.shape[1],\n",
    "              nhid=16,\n",
    "              nclass=labels.max().item() + 1,\n",
    "              dropout=0.5, device=device)\n",
    "\n",
    "    target_gcn = target_gcn.to(device)\n",
    "\n",
    "    target_gcn.fit(features, adj, labels, idx_train, idx_val, patience=30)\n",
    "\n",
    "    cnt = 0\n",
    "    degrees = adj.sum(0).A1\n",
    "    node_list = select_nodes(target_gcn)\n",
    "    num = len(node_list)\n",
    "\n",
    "    print('=== [Evasion] Attacking %s nodes respectively ===' % num)\n",
    "    for target_node in tqdm(node_list):\n",
    "        n_perturbations = int(degrees[target_node])\n",
    "        model = RND()\n",
    "        model = model.to(device)\n",
    "        model.attack(adj, labels, idx_train, target_node, n_perturbations, verbose=False)\n",
    "        model.add_nodes(features, adj, labels, idx_train, target_node, n_added=40,\n",
    "                               n_perturbations=n_perturbations)\n",
    "        modified_adj = model.modified_adj\n",
    "        modified_features = model.modified_features\n",
    "        #print(modified_adj)\n",
    "        print(modified_features)\n",
    "        acc = single_test(modified_adj, modified_features, target_node, gcn=target_gcn)\n",
    "        if acc == 0:\n",
    "            cnt += 1\n",
    "    print('misclassification rate : %s' % (cnt/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('=== testing GCN on original(clean) graph ===')\n",
    "    test(adj, features, target_node)\n",
    "    print('=== testing GCN on perturbed graph ===')\n",
    "    if modified_features is None:\n",
    "        test(modified_adj, features, target_node)\n",
    "    else:\n",
    "        test(modified_adj, modified_features, target_node)\n",
    "\n",
    "    return modified_features\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== testing GCN on original(clean) graph ===\n",
      "probs: {probs.detach().cpu().numpy()}\n",
      "Test set results: loss= 1.3053 accuracy= 0.7227\n",
      "=== testing GCN on perturbed graph ===\n",
      "probs: {probs.detach().cpu().numpy()}\n",
      "Test set results: loss= 1.2632 accuracy= 0.7145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    mf = main()\n",
    "   # multi_test_evasion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
